Gradient Descent Algorithm in Multiple Linear Regression
I used the gradient descent algorithm in multiple linear regression to minimize the cost function and find the best-fitting line for a dataset. 
To explore this, I applied both a manual approach and Python programming to understand the intuition behind the process.
I created a problem using a dataset with two input features and one output variable. I analyzed it using the mean squared error (MSE) as the cost function.
For the manual calculations, I performed two iterations. This process was time-consuming and mathematically demanding because it required an understanding of matrix multiplication,
dot products, and matrix transposition. However, in the end, the manual calculations yielded the same results as the Python implementation.
Additionally, I included a stopping criterion in the code to exit the loop once a specified threshold was met.
